# ğŸ¤ AI Voice Customer Support Agent (Gemini + Whisper + Gradio)

An intelligent voice-enabled customer support system powered by **Gemini 2.0 Flash**, **OpenAI Whisper**, and **gTTS**, built with a clean conversational UI using **Gradio** and fully deployed on **HuggingFace Spaces**.

This project allows users to speak or type queries, receive AI-generated responses, hear voice replies, and view full conversation history â€” all in a smooth, interactive interface.

---

## ğŸš€ Features

âœ… Real-time **voice input** using OpenAI Whisper  
âœ… Gemini-based conversational AI responses  
âœ… **Text-to-Speech** output using gTTS  
âœ… Clean multi-tab **Gradio interface**  
&nbsp;&nbsp;&nbsp;â€¢ API Key tab  
&nbsp;&nbsp;&nbsp;â€¢ Chat tab  
&nbsp;&nbsp;&nbsp;â€¢ History tab  
âœ… Full conversation memory & history  
âœ… Deployed on **HuggingFace Spaces**  
âœ… Supports both text and voice conversations  
âœ… Lightweight, fast, and easy to run

---

## ğŸŒ Live Demo (HuggingFace)

ğŸ‘‰ **Try it here:**  
https://huggingface.co/spaces/johndonal/AI-Voice-Agent

No installation needed â€” everything runs in the cloud.

---

## ğŸ§© Tech Stack

- **Gemini 2.0 Flash** â€“ AI conversation engine  
- **Whisper (base)** â€“ Automatic Speech Recognition  
- **gTTS** â€“ Neural voice generation  
- **Gradio** â€“ Multi-tab UI  
- **Python** â€“ Core logic  
- **HuggingFace Spaces** â€“ Deployment platform  

---

## ğŸ› ï¸ How It Works

The system uses a simple pipeline:

**Voice â†’ STT (Whisper) â†’ Gemini AI â†’ TTS (gTTS) â†’ Voice Response**

---

<details>
<summary><strong>ğŸ™ï¸ STT (Speech-to-Text) â€“ How It Works</strong></summary>
<br>

Whisper converts audio â†’ text through these steps:

1. ğŸ¤ **Audio Input** â€“ User speaks.
2. ğŸ”¢ **Sampling** â€“ Converts sound waves into digital numbers.
3. ğŸ“ˆ **Waveform** â€“ List of numbers representing loudness over time.
4. âœ‚ï¸ **Framing** â€“ Slices audio into tiny chunks.
5. ğŸƒ **Windowing** â€“ Smooths the slices.
6. ğŸ–¼ï¸ **Spectrogram** â€“ Creates a picture of sound (time vs frequency).
7. ğŸšï¸ **Mel-Spectrogram** â€“ Version optimized for human hearing.
8. ğŸ§  **Neural Network Processing** â€“ Whisper understands speech patterns.
9. ğŸ”¡ **Token Prediction** â€“ Predicts text fragments.
10. ğŸ“ **Final Text Output** â€“ Forms the sentence.

<strong>Simple Summary:</strong> voice â†’ numbers â†’ sound image â†’ AI â†’ text
</details>

---

<details>
<summary><strong>ğŸ”Š TTS (Text-to-Speech) â€“ How It Works</strong></summary>
<br>

gTTS converts text â†’ human-like voice through these steps:

1. ğŸ§¹ **Text Normalization** â€“ Clean & prepare text for speaking.
2. âœ‚ï¸ **Tokenization** â€“ Split text into small pieces.
3. ğŸ”Š **Phoneme Conversion** â€“ Words â†’ pronunciation sounds.
4. ğŸ¼ **Prosody Modeling** â€“ Emotion, tone, pauses.
5. ğŸ–¼ï¸ **Mel-Spectrogram Generation** â€“ Blueprint of how speech should sound.
6. ğŸ›ï¸ **Vocoder** â€“ Converts spectrogram â†’ real audio.
7. ğŸŒŠ **Waveform Synthesis** â€“ Creates final voice waveform.
8. ğŸ’¾ **Audio Encoding** â€“ Converts waveform into MP3/WAV.
9. â–¶ï¸ **Playback** â€“ User hears the output.

<strong>Simple Summary:</strong> text â†’ sounds â†’ spectrogram â†’ vocoder â†’ speech
</details>

---

## ğŸ”„ STT + AI + TTS Pipeline (Visual Diagram)

```
      ğŸ¤ User Voice
            â”‚
            â–¼
   ğŸ™ï¸ Whisper STT (Speech-to-Text)
            â”‚
            â–¼
       ğŸ“ Text Content
            â”‚
            â–¼
      ğŸ¤– Gemini AI Response
            â”‚
            â–¼
      ğŸ”Š gTTS (Text-to-Speech)
            â”‚
            â–¼
       ğŸ§ AI Voice Output
```


---

## ğŸ“‚ Project Structure

```
AI-Voice-Agent/
â”‚
â”œâ”€â”€ app.py            # Main Gradio application (UI + logic)
â”œâ”€â”€ model.py          # Gemini model configuration + response logic
â”œâ”€â”€ sst.py            # Whisper speech-to-text module
â”œâ”€â”€ tts.py            # gTTS text-to-speech module
â”œâ”€â”€ requirements.txt  # Dependencies for HuggingFace or local run
â””â”€â”€ README.md         # Documentation
```

---

## â–¶ï¸ Demo Preview

<p align="center">
  <a href="https://raw.githubusercontent.com/MuhammadMusabYaqoob/AI-Voice-Customer-Support-Agent/main/demo.mp4">
    <img src="https://img.shields.io/badge/â–¶ï¸ Click_to_Watch_Demo-FF0000?style=for-the-badge" width="300"/>
  </a>
</p>

<p align="center">
  <video width="700" controls>
    <source src="https://raw.githubusercontent.com/MuhammadMusabYaqoob/AI-Voice-Customer-Support-Agent/main/demo.mp4" type="video/mp4">
  </video>
</p>

Use the following actions in the app:

1. Enter your **Gemini API Key**  
2. Open the **Chat** tab  
3. Record your voice OR type a message  
4. Listen to the AIâ€™s audio reply  
5. View full conversation in the **History** tab  

Perfect for showing voice-based AI interactions in customer support use cases.

---

## ğŸ’¡ Example Use-Cases

- Customer service automation  
- AI voice support demos  
- IVR-style automated phone systems  
- Smart assistants  
- Educational AI showcases  

---

## âš™ï¸ Installation (Run Locally)

```bash
git clone https://github.com/yourusername/AI-Voice-Agent
cd AI-Voice-Agent
pip install -r requirements.txt
python app.py
```

Make sure you add your:

```
GEMINI_API_KEY
```

before chatting.

---

## ğŸ§‘â€ğŸ’» Author

**Muhammad Musab**  
ğŸŒ GitHub: https://github.com/muhammadmusabyaqoob  
ğŸ“§ musabyaqoob2@gmail.com  

---

## ğŸ·ï¸ Tags

`Gemini` `Whisper` `gTTS` `Gradio` `Speech Recognition` `Text-to-Speech` `AI Voice Agent` `Customer Support` `Automation` `HuggingFace`

---

## ğŸŒŸ Badges

![HuggingFace](https://img.shields.io/badge/Deploy-HuggingFace-blue?style=for-the-badge)
![Gemini](https://img.shields.io/badge/AI-Gemini%202.0%20Flash-yellow?style=for-the-badge)
![Whisper](https://img.shields.io/badge/ASR-Whisper-green?style=for-the-badge)
![Gradio](https://img.shields.io/badge/UI-Gradio-orange?style=for-the-badge)
